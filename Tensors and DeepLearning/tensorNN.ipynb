{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efbd7cd8-3ebd-4152-b7f6-eafeb98a84ee",
   "metadata": {},
   "source": [
    "Lets create a simple Tensor-likes \"Tensors\". So we are just gonna think of tensors, but in the end, they are a bit different to this. However, it has the same bases.\\\n",
    "A vector are $x_i$ values in $R^1$, a matrix are $x_i$ values in $R^2$.\\\n",
    "And the new: The tensor is $R^i$ higher than $i > 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75e449c-8d9e-4e0b-b319-7715f718bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45660e0-a203-4310-90de-a77559e79f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b41b5451-14f7-48cb-a854-7f3878216539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(tensor: Tensor) -> List[int]:\n",
    "    sizes: List[int] = []\n",
    "    while isinstance(tensor, list):\n",
    "        sizes.append(len(tensor))\n",
    "        tensor = tensor[0]\n",
    "    return sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2061aea-c8a4-4260-9c16-bb2e8312593a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c2d99-382f-45ee-9ae3-a5f6a6034366",
   "metadata": {},
   "source": [
    "If the tensor is $R^1$ then is a vector, however if the tensor has a list or vector or even a matrix in its index, then its a higher-order tensor.\\\n",
    "Lets create a function to know this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94078a9e-da78-4ec1-abd8-e5b2403fa005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_1d(tensor: Tensor) -> bool:\n",
    "    return not isinstance(tensor[0], list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb0cfc42-9eac-4d5e-a9a1-e5399d9c15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor summatory\n",
    "def tensor_sum(tensor: Tensor) -> float:\n",
    "    if is_1d(tensor):\n",
    "        return sum(tensor) # We can use ordinary Python sum\n",
    "    else:\n",
    "        return sum(tensor_sum(tensor_i) for tensor_i in tensor) # We use itirable sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97faeec3-6dd4-4c52-92e4-df0cc0f9f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "def tensor_apply(f: Callable[[float], float], tensor: Tensor) -> Tensor:\n",
    "    if is_1d(tensor):\n",
    "        return [f(x) for x in tensor]\n",
    "    else:\n",
    "        return [tensor_apply(f, tensor_i) for tensor_i in tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e8346c-5bc2-405c-a23b-eb4e3c19d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tensor_apply(lambda x: x + 1, [1, 2, 3]) == [2, 3, 4]\n",
    "assert tensor_apply(lambda x: 2 * x, [[1, 2], [3, 4]]) == [[2, 4], [6, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8eb7afe-bae3-43f6-acb5-abf07ff71bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros_like(tensor: Tensor) -> Tensor:\n",
    "    return tensor_apply(lambda _: 0.0, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7211a123-15b2-4dbb-a0b2-18164ee47cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_combine(f: Callable[[float, float], float], t1: Tensor, t2: Tensor) -> Tensor:\n",
    "    if is_1d(t1):\n",
    "        return [f(x, y) for x, y in zip(t1, t2)]\n",
    "    else:\n",
    "        return [tensor_combine(f, t1_i, t2_i) for t1_i, t2_i in zip(t1, t2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6623ffa4-a0f3-47b9-a276-dc9fe025ec76",
   "metadata": {},
   "source": [
    "Ok, we just created the basic functions to start working and creating better NeuralNetworks. We added summatory, component sum, and a generalized method for functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84fcc44e-c9be-4638-9b88-e8636d3332f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    Our neural networks will be composed of Layers, each of which\n",
    "    knows how to do some computation on its inputs in the \"forward\"\n",
    "    direction and propagate gradients in the \"backward\" direction.\n",
    "    \"\"\"\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Note the lack of types. We're not going to be prescriptive\n",
    "        about what kinds of inputs layers can take and what kinds\n",
    "        of outputs they can return.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    def backward(self, gradient):\n",
    "        \"\"\"\n",
    "        Similarly, we're not going to be prescriptive about what the\n",
    "        gradient looks like. It's up to you the user to make sure\n",
    "        that you're doing things sensibly.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    def params(self) -> Iterable[Tensor]:\n",
    "        \"\"\"\n",
    "        Returns the parameters of this layer. The default implementation\n",
    "        returns nothing, so that if you have a layer with no parameters\n",
    "        you don't have to implement this.\n",
    "        \"\"\"\n",
    "        return ()\n",
    "    def grads(self) -> Iterable[Tensor]:\n",
    "        \"\"\"\n",
    "        Returns the gradients, in the same order as params().\n",
    "        \"\"\"\n",
    "        return ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09cb0467-c576-4d03-9d2b-09633664c3ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m  \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sigmoid\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSigmoid\u001b[39;00m(Layer):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "from  models import sigmoid\n",
    "class Sigmoid(Layer):\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Apply sigmoid to each element of the input tensor,\n",
    "        and save the results to use in backpropagation.\n",
    "        \"\"\"\n",
    "        self.sigmoids = tensor_apply(sigmoid, input)\n",
    "        return self.sigmoids\n",
    "    def backward(self, gradient: Tensor) -> Tensor:\n",
    "        return tensor_combine(lambda sig, grad: sig * (1 - sig) * grad, self.sigmoids, gradient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
